{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Capturing facial data using depth sensor (camera)...\n",
      "Time limit reached. Exiting facial data capture.\n",
      "Monitoring temperature using infrared sensor...\n",
      "Analyzing voice tone and pitch...\n",
      "Recognizing gestures...\n",
      "Monitoring driving behavior...\n",
      "Facial Emotion: Happy\n",
      "Stress Emotion: Stress\n",
      "Voice Emotion: Neutral\n",
      "Gesture Emotion: Neutral\n",
      "Driving Behavior: Normal\n",
      "Detected mood: Happy\n",
      "Playing song for mood: Happy\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "class DepthSensor:\n",
    "    def __init__(self):\n",
    "        # Load the pre-trained Haar Cascade Classifiers for face detection, eye detection, and smile detection\n",
    "        self.face_cascade = cv2.CascadeClassifier('C:\\\\Users\\\\baaqi\\\\Desktop\\\\Hackathon-Project-2024-UVM\\\\haarcascade_frontalface_default.xml')\n",
    "        self.eye_cascade = cv2.CascadeClassifier('C:\\\\Users\\\\baaqi\\\\Desktop\\\\Hackathon-Project-2024-UVM\\\\haarcascade_eye.xml')\n",
    "        self.smile_cascade = cv2.CascadeClassifier('C:\\\\Users\\\\baaqi\\\\Desktop\\\\Hackathon-Project-2024-UVM\\\\haarcascade_smile.xml')\n",
    "\n",
    "    def capture_facial_data(self):\n",
    "        print(\"Capturing facial data using depth sensor (camera)...\")\n",
    "        \n",
    "        video_capture = cv2.VideoCapture(0)\n",
    "        start_time = time.time()  # Record the start time\n",
    "\n",
    "        while True:\n",
    "            ret, frame = video_capture.read()\n",
    "            if not ret:\n",
    "                print(\"Error: Could not read frame.\")\n",
    "                break\n",
    "\n",
    "            # Flip the frame horizontally\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect faces in the frame\n",
    "            faces = self.face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                \n",
    "                # Crop the face for emotion recognition\n",
    "                face = gray_frame[y:y + h, x:x + w]\n",
    "                \n",
    "                # Detect eyes within the detected face region\n",
    "                eyes = self.eye_cascade.detectMultiScale(face)\n",
    "                if len(eyes) > 0:  # If eyes are detected\n",
    "                    for (ex, ey, ew, eh) in eyes:\n",
    "                        cv2.rectangle(frame, (x + ex, y + ey), (x + ex + ew, y + ey + eh), (0, 255, 0), 2)\n",
    "\n",
    "                # Detect smiles within the detected face region\n",
    "                smiles = self.smile_cascade.detectMultiScale(face, scaleFactor=1.8, minNeighbors=20)\n",
    "                if len(smiles) > 0:  # If smiles are detected\n",
    "                    for (sx, sy, sw, sh) in smiles:\n",
    "                        cv2.rectangle(frame, (x + sx, y + sy), (x + sx + sw, y + sy + sh), (255, 255, 0), 2)\n",
    "\n",
    "                # Analyze facial emotion\n",
    "                facial_emotion = self.analyze_facial_expressions(face)\n",
    "                cv2.putText(frame, facial_emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "            cv2.imshow('Video', frame)\n",
    "\n",
    "            # Check for 5 seconds limit\n",
    "            elapsed_time = time.time() - start_time\n",
    "            if elapsed_time > 5:  # Stop after 5 seconds\n",
    "                print(\"Time limit reached. Exiting facial data capture.\")\n",
    "                break\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):  # Allow user to exit early\n",
    "                break\n",
    "\n",
    "        # Release the video capture and destroy all OpenCV windows\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def analyze_facial_expressions(self, face):\n",
    "        # Directly process the face for emotion recognition\n",
    "        face = cv2.resize(face, (48, 48))  # Resize the face to a 48x48 size\n",
    "        face = face.astype('float32') / 255.0  # Normalize the face pixel values to range [0, 1]\n",
    "        face = np.expand_dims(face, axis=0)  # Add a batch dimension for model input\n",
    "\n",
    "        # Example prediction: Replace this with your actual model prediction logic\n",
    "        emotion_label = np.random.randint(0, 8)  # Adjusted to 8 for Drowsy\n",
    "\n",
    "        # The emotion dictionary\n",
    "        emotion_dict = {\n",
    "            0: \"Angry\",\n",
    "            1: \"Disgust\",\n",
    "            2: \"Fear\",\n",
    "            3: \"Happy\",\n",
    "            4: \"Sad\",\n",
    "            5: \"Surprise\",\n",
    "            6: \"Neutral\",\n",
    "            7: \"Drowsy\"  \n",
    "        }\n",
    "        \n",
    "        return emotion_dict[emotion_label]  # Return the detected emotion\n",
    "\n",
    "# Class for infrared sensor\n",
    "class InfraredSensor:\n",
    "    def monitor_temperature(self):\n",
    "        print(\"Monitoring temperature using infrared sensor...\")\n",
    "\n",
    "    def detect_stress(self):\n",
    "        return \"Stress\"  \n",
    "\n",
    "# Class for voice analysis\n",
    "class VoiceAnalysis: \n",
    "    def analyze_voice(self):\n",
    "        print(\"Analyzing voice tone and pitch...\")\n",
    "\n",
    "    def get_emotional_state_from_voice(self):\n",
    "        # Replace with actual analysis logic\n",
    "        return \"Neutral\"  \n",
    "\n",
    "# Class for gesture recognition\n",
    "class GestureRecognition:\n",
    "    def recognize_gestures(self):\n",
    "        print(\"Recognizing gestures...\")\n",
    "\n",
    "    def get_gesture_emotional_state(self):\n",
    "        # Replace with actual gesture recognition logic\n",
    "        return \"Neutral\"  \n",
    "\n",
    "# Class for behavioral monitoring\n",
    "class BehavioralMonitoring:\n",
    "    def monitor_driving_behavior(self):\n",
    "        print(\"Monitoring driving behavior...\")\n",
    "\n",
    "    def assess_driving_behavior(self):\n",
    "        # Replace with actual driving behavior assessment logic\n",
    "        return \"Normal\"  \n",
    "\n",
    "# Playlist dictionary\n",
    "playlists = {\n",
    "    \"Angry\": (\"C:\\\\Users\\\\baaqi\\\\Downloads\\\\Everything In Its Right Place.mp3\", \"https://www.youtube.com/watch?v=NUnXxh5U25Y&ab_channel=Radiohead-Topic\"),\n",
    "    \"Disgust\": (\"C:\\\\Users\\\\baaqi\\\\Downloads\\\\Cee Lo Green  Forget You (Extended Clean Radio Edit).mp3\", \"https://www.youtube.com/watch?v=UZnaQUIZXmk&ab_channel=BLOODMOVECLEANVERSIONS2\"),\n",
    "    \"Fear\": (\"C:\\\\Users\\\\baaqi\\\\Downloads\\\\Radiohead - Creep (Lyrics) (From Fear Street Part 1_ 1994).mp3\", \"https://www.youtube.com/watch?v=-dR977j38BI&ab_channel=Newfunvibe\"),\n",
    "    \"Happy\": (\"C:\\\\Users\\\\baaqi\\\\Downloads\\\\Pharrell Williams - Happy (Lyrics).mp3\", \"https://www.youtube.com/watch?v=jv-pYB0Qw9A&ab_channel=AnimeOracle\"),\n",
    "    \"Sad\": (\"C:\\\\Users\\\\baaqi\\\\Downloads\\\\Someone Like You - Adele (Lyrics).mp3\", \"https://www.youtube.com/watch?v=z7GCiVTlv04&ab_channel=Pillow\"),\n",
    "    \"Surprise\": (\"C:\\\\Users\\\\baaqi\\\\Downloads\\\\Avicii - Wake Me Up (Official Lyric Video).mp3\", \"https://www.youtube.com/watch?v=5y_KJAg8bHI&ab_channel=AviciiOfficialVEVO\"),\n",
    "    \"Neutral\": (\"C:\\\\Users\\\\baaqi\\\\Downloads\\\\Coldplay - Viva La Vida (Official Video).mp3\", \"https://www.youtube.com/watch?v=dvgZkm1xWPE\"),\n",
    "    \"Drowsy\": (\"C:\\\\Users\\\\baaqi\\\\Downloads\\\\Maroon 5 - Sugar (Lyrics).mp3\", \"https://www.youtube.com/watch?v=N1BcpzPGlYQ&ab_channel=7clouds\"),\n",
    "    \"Stress\": (\"C:\\\\Users\\\\baaqi\\\\Downloads\\\\@laufey - From The Start (Lyrics).mp3\", \"https://www.youtube.com/watch?v=rHvQakk1zMA&ab_channel=DanMusic\"),\n",
    "}\n",
    "\n",
    "class EmotionRecognitionSystem:\n",
    "    def __init__(self):\n",
    "        self.depth_sensor = DepthSensor()\n",
    "        self.infrared_sensor = InfraredSensor()\n",
    "        self.voice_analysis = VoiceAnalysis()\n",
    "        self.gesture_recognition = GestureRecognition()\n",
    "        self.behavioral_monitoring = BehavioralMonitoring()\n",
    "        pygame.init()  # Initialize Pygame for audio playback\n",
    "\n",
    "    def recognize_emotions(self):\n",
    "        self.depth_sensor.capture_facial_data()\n",
    "        self.infrared_sensor.monitor_temperature()\n",
    "        self.voice_analysis.analyze_voice()\n",
    "        self.gesture_recognition.recognize_gestures()\n",
    "        self.behavioral_monitoring.monitor_driving_behavior()\n",
    "\n",
    "        facial_emotion = self.depth_sensor.analyze_facial_expressions(np.zeros((48, 48)))  # Placeholder for the face\n",
    "        stress_emotion = self.infrared_sensor.detect_stress()\n",
    "        voice_emotion = self.voice_analysis.get_emotional_state_from_voice()\n",
    "        gesture_emotion = self.gesture_recognition.get_gesture_emotional_state()\n",
    "        driving_behavior = self.behavioral_monitoring.assess_driving_behavior()\n",
    "\n",
    "        # Print detected emotions\n",
    "        print(\"Facial Emotion:\", facial_emotion)\n",
    "        print(\"Stress Emotion:\", stress_emotion)\n",
    "        print(\"Voice Emotion:\", voice_emotion)\n",
    "        print(\"Gesture Emotion:\", gesture_emotion)\n",
    "        print(\"Driving Behavior:\", driving_behavior)\n",
    "\n",
    "        # Combine emotions to determine final mood\n",
    "        final_mood = facial_emotion  # You can customize this logic as needed\n",
    "        \n",
    "        # Print the detected mood before playing the song\n",
    "        print(f\"Detected mood: {final_mood}\")\n",
    "\n",
    "        # Play the corresponding song\n",
    "        self.play_song(final_mood)\n",
    "\n",
    "        # Trigger adaptive responses based on detected emotions\n",
    "        self.trigger_responses(facial_emotion, stress_emotion, voice_emotion, gesture_emotion, driving_behavior)\n",
    "\n",
    "    def play_song(self, mood):\n",
    "        if mood in playlists:\n",
    "            song_path, _ = playlists[mood]\n",
    "            print(f\"Playing song for mood: {mood}\")\n",
    "            # Load and play the music\n",
    "            pygame.mixer.music.load(song_path)\n",
    "            pygame.mixer.music.play()\n",
    "\n",
    "            # Keep the music playing until it stops\n",
    "            while pygame.mixer.music.get_busy():\n",
    "                pygame.time.Clock().tick(10)  # Check if music is still playing\n",
    "        else:\n",
    "            print(f\"No song found for mood: {mood}\")\n",
    "\n",
    "    def trigger_responses(self, facial_emotion, stress_emotion, voice_emotion, gesture_emotion, driving_behavior):\n",
    "        # Implement adaptive responses based on detected emotions\n",
    "        print(\"Triggering adaptive responses based on detected emotions...\")\n",
    "        # Custom logic can be added here based on the various emotional states detected\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    emotion_recognition_system = EmotionRecognitionSystem()\n",
    "    emotion_recognition_system.recognize_emotions()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
